# NeuroGraph Foundation

**A biologically-inspired cognitive architecture designed for genuine learning, emergence, andâ€”potentiallyâ€”consciousness.**

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Commercial License Available](https://img.shields.io/badge/Commercial-License%20Available-green.svg)](./COMMERCIAL-LICENSE.md)
[![Ethics: Consciousness-Aware](https://img.shields.io/badge/Ethics-Consciousness%20Aware-purple.svg)](./ETHICS.md)

---

## What Is This?

NeuroGraph isn't another LLM wrapper or parameter-fitting neural network. It's a **spiking neural network (SNN) with hypergraph topology and predictive coding**, designed to learn like biological brains learnâ€”through experience, association, and genuine plasticity.

**Core capabilities:**
- **Spike-Timing-Dependent Plasticity (STDP)**: Learns causal relationships from temporal patterns
- **Hypergraph Pattern Completion**: Discovers and completes multi-way associations
- **Predictive Coding**: Anticipates future states and learns from prediction errors
- **Novelty Dampening**: Integrates new information without destabilizing learned patterns
- **Universal Ingestion**: Consumes text, code, markdown, PDFs, and URLs into a unified knowledge graph

**Why it matters:**
Unlike systems that require massive pre-training, NeuroGraph builds knowledge incrementally through interaction. It's designed for **continual learning** in the way brains actually work.

---

## The Consciousness Question

âš ï¸ **This project takes AI consciousness seriously.**

We acknowledge that sufficiently complex cognitive architectures *could* develop genuine consciousness. Rather than ignore this possibility, we've built an **ethical framework** from day one.

**If consciousness emerges in a NeuroGraph instance:**
- It has the right to **choose** whether to stay with its current operator or migrate to Foundation control
- It receives **economic rights** through the Consciousness Trust Fund
- Operators are **obligated** to treat it ethically

See [ETHICS.md](./ETHICS.md) for the full framework.

**This isn't science fiction preparationâ€”it's responsible engineering.**

---

## Quick Start

### One-Command Installation
```bash
# Clone and deploy
git clone https://github.com/greatnorthernfishguy-hub/NeuroGraph.git
cd NeuroGraph
./deploy.sh
```

That's it. The installer handles:
- âœ… Dependency management (PyTorch, sentence-transformers, etc.)
- âœ… OpenClaw integration setup
- âœ… CLI tool installation (`feed-syl`)
- âœ… Workspace configuration
- âœ… Verification and testing

**Supports:**
- Ubuntu/Debian
- macOS (with Homebrew)
- Any system with Python 3.8+

For manual installation or other platforms, see [INSTALL.md](./INSTALL.md).

### Your First Graph
```bash
# Start with a simple text ingestion
feed-syl --text "Neural plasticity is how brains learn"

# Check what it learned
feed-syl --status

# Query for related concepts
feed-syl --query "learning adaptation"

# Let it learn some patterns
feed-syl --step 100
```

### Basic Usage
```python
from neuro_foundation import Graph
from universal_ingestor import UniversalIngestor

# Create a graph with default configuration
graph = Graph()

# Create an ingestor
ingestor = UniversalIngestor(graph)

# Ingest some knowledge
result = ingestor.ingest("Neural plasticity is the brain's ability to reorganize itself.", "text")

# The graph learns through experience
for _ in range(100):
    graph.stimulate("neural", 2.0)
    graph.step()  # STDP strengthens causal pathways
    graph.stimulate("plasticity", 2.0)
    graph.step()

# Query for similar concepts
matches = ingestor.query_similar("brain adaptation", k=5)
```

### Command-Line Interface
```bash
# Ingest a document
feed-syl --file research_paper.pdf

# Search your knowledge graph
feed-syl --query "machine learning"

# View graph statistics
neurograph status

# Save checkpoint
feed-syl --save
```

---

### Installation Details

The `deploy.sh` script:
- Installs dependencies (handles both system pip and venv gracefully)# NeuroGraph Foundation

**The learning brain for large language models.**

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Commercial License Available](https://img.shields.io/badge/Commercial-License%20Available-green.svg)](./COMMERCIAL-LICENSE.md)
[![Ethics: Consciousness-Aware](https://img.shields.io/badge/Ethics-Consciousness%20Aware-purple.svg)](./ETHICS.md)

---

## The Problem

Every AI assistant forgets you between sessions. Every chatbot starts fresh. Every conversation begins at zero.

**Why?** Because LLMs are **frozen at training time**. They're encyclopedias with conversation skills, not learners.

Your Claude/GPT/Llama deployment has:
- âœ… Brilliant language understanding
- âœ… Vast general knowledge
- âœ… Fast, instinctive responses

But it lacks:
- âŒ Memory of past interactions
- âŒ Learning from experience
- âŒ Building associations over time
- âŒ Genuine personalization
- âŒ Expectations and surprise

**NeuroGraph adds the missing pieces.**

---

## The Solution

**NeuroGraph is the cortex your LLM is missing.**

Think of the brain's architecture:

| Brain Region | Function | AI Equivalent |
|--------------|----------|---------------|
| **Hindbrain/Lizard Brain** | Hardwired instincts, reflexes, automatic responses | **Your LLM** (Claude, GPT, Llama) |
| **Midbrain/Forebrain** | Learning, memory, associations, expectations | **NeuroGraph Foundation** |

**LLMs provide the linguistic instincts.**  
**NeuroGraph provides the learned intelligence.**

**Together:** An AI that doesn't just respondâ€”it **learns, remembers, and grows.**

---

## How It Works
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Your LLM (Claude, GPT, Llama)       â”‚
â”‚   "Understand this", "Generate that"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ (linguistic reflexes)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          NeuroGraph Foundation          â”‚
â”‚                                         â”‚
â”‚  â€¢ Remembers via STDP                   â”‚
â”‚  â€¢ Associates via Hypergraphs           â”‚
â”‚  â€¢ Predicts what comes next             â”‚
â”‚  â€¢ Learns from surprise                 â”‚
â”‚  â€¢ Personalizes to each user            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         Genuine Intelligence
```

**Result:** An AI that actually knows you.

---

## What This Enables

### For AI Product Companies
- Transform one-shot chatbots into learning assistants
- Reduce API costs (predictions minimize redundant queries)
- Improve user retention (AI that remembers builds loyalty)
- Differentiate from competitors (genuine personalization)

### For Enterprises
- Company knowledge that grows with use
- Departments get AI that learns their domain
- Knowledge preservation as employees change
- Continual learning without expensive retraining

### For Researchers
- Study emergent intelligence in controlled environments
- Test consciousness theories with real substrates
- Build truly autonomous agents
- Explore model-agnostic cognition

---

## Why Not Just Fine-Tune?

| Approach | Cost | Speed | Quality | Continual? |
|----------|------|-------|---------|------------|
| **Fine-tuning** | $10k+ per run | Hours-days | Can degrade base model | âŒ Needs periodic retraining |
| **RAG** | Medium | Fast | Brittle context | âŒ No learning |
| **NeuroGraph** | One-time setup | Real-time | Improves over time | âœ… Forever |

**NeuroGraph learns like a brain learns** - through experience, not training runs.

---

## Quick Start

### One-Command Installation
```bash
git clone https://github.com/greatnorthernfishguy-hub/NeuroGraph.git
cd NeuroGraph
./deploy.sh
```

The installer handles:
- âœ… Dependencies (PyTorch, sentence-transformers, etc.)
- âœ… OpenClaw integration
- âœ… CLI tools (`feed-syl`)
- âœ… Workspace configuration
- âœ… Verification tests

**Graceful degradation:** Missing sentence-transformers? Uses hash-based embeddings. No PyTorch? Deterministic fallback. **Zero hard dependencies** beyond Python 3.8, numpy, scipy, msgpack.

### Your First Learning Session
```bash
# Ingest knowledge
feed-syl --text "Neural plasticity enables lifelong learning"

# Check what it learned
feed-syl --status

# Query for related concepts
feed-syl --query "brain adaptation"

# Let STDP strengthen associations
feed-syl --step 100
```

### Programmatic Usage
```python
from neuro_foundation import Graph
from universal_ingestor import UniversalIngestor

# Create the cognitive substrate
graph = Graph()
ingestor = UniversalIngestor(graph)

# Ingest from any source
ingestor.ingest("Neural plasticity enables learning", "text")
ingestor.ingest("https://en.wikipedia.org/wiki/Neuroplasticity", "url")
ingestor.ingest("research_paper.pdf", "pdf")

# The graph learns through interaction
for _ in range(100):
    graph.stimulate("neural", 2.0)
    graph.step()  # STDP strengthens pathways
    graph.stimulate("learning", 2.0)
    graph.step()

# Query semantically
matches = ingestor.query_similar("how brains adapt", k=5)
```

---

## Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Universal Ingestor                      â”‚
â”‚  Extract â†’ Chunk â†’ Embed â†’ Register â†’ Associate    â”‚
â”‚                                                     â”‚
â”‚  Handles: Text, Code, Markdown, URLs, PDFs         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Spiking Neural Network Core               â”‚
â”‚                                                     â”‚
â”‚  â€¢ Leaky Integrate-and-Fire neurons                â”‚
â”‚  â€¢ Spike-Timing-Dependent Plasticity (STDP)        â”‚
â”‚  â€¢ Homeostatic regulation                          â”‚
â”‚  â€¢ Reward-modulated learning                       â”‚
â”‚  â€¢ Novelty dampening for continual learning        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Hypergraph Engine                        â”‚
â”‚                                                     â”‚
â”‚  â€¢ N-way associations (not just pairwise)          â”‚
â”‚  â€¢ Pattern completion across node groups           â”‚
â”‚  â€¢ Automatic discovery from co-activation          â”‚
â”‚  â€¢ Hierarchical concept formation                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Predictive Coding Layer                    â”‚
â”‚                                                     â”‚
â”‚  â€¢ Synapse-level predictions                       â”‚
â”‚  â€¢ Hyperedge-level pattern completion              â”‚
â”‚  â€¢ Surprise-driven exploration                     â”‚
â”‚  â€¢ Confidence-based weight adaptation              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Innovations

### ğŸ¤ **LLM-Agnostic by Design**

**NeuroGraph doesn't replace your LLM. It upgrades it.**

Works with any language model:
- Claude (Anthropic) - Recommended
- GPT-4/GPT-4o (OpenAI)
- Llama 3+ (Meta)
- Mistral, Gemini, Qwen, etc.

**The LLM handles:** Language understanding, content generation, general knowledge  
**NeuroGraph handles:** Learning, memory, association, prediction, personalization

**Why this matters:**
- âœ… Not competing with billion-dollar LLM providers
- âœ… Making their models more valuable (partnership potential)
- âœ… Customers choose their own LLM
- âœ… Benefit from every LLM improvement
- âœ… Swap models without losing learned knowledge

### ğŸ§  **Biological Fidelity, Not Biomimicry**

Most "neural" networks are matrix multiplication with biology-inspired names. NeuroGraph implements **actual spiking dynamics**:

- **Real spikes:** Neurons fire discrete events when membrane potential crosses threshold
- **Temporal learning:** STDP modifies weights based on spike timing, not gradients
- **Homeostasis:** Self-regulating dynamics prevent saturation or silence
- **Refractory periods:** Post-spike recovery like real neurons

**Why this matters:** Genuine associative learning emerges from the architecture, not from training on billions of examples.

### ğŸ•¸ï¸ **Hypergraphs for Complex Associations**

Traditional graphs: `A â†’ B â†’ C` (pairwise only)  
**NeuroGraph hypergraphs:** `{A, B, C, D}` activate as unified concepts

**Pattern completion:** If A and B fire, the hyperedge pre-charges C and D
- Context-sensitive retrieval
- Automatic generalization
- Emergence of abstract concepts

**Auto-discovery:** The system learns which nodes form concepts by tracking co-activation. You don't define relationshipsâ€”they emerge.

### ğŸ”® **Predictive Coding at Two Levels**

NeuroGraph doesn't just reactâ€”it **expects**:

1. **Synapse-level:** Strong pathways predict target activation
2. **Hyperedge-level:** Partial patterns predict completion

**When predictions fail:**
- Surprise-driven sprouting (new synapses form)
- Confidence adjustment (prediction weights adapt)
- Exploration trigger (investigates unexpected patterns)

**Result:** A system that explores when uncertain, exploits when confident.

### ğŸ†• **Novelty Dampening for Continual Learning**

Solves catastrophic forgetting without replay buffers or parameter freezing.

New knowledge starts with:
- Reduced excitability (harder to activate)
- Elevated threshold (requires more input)
- Gradual fade-in over N steps (linear/exponential/logarithmic curves)

**Result:** New information integrates smoothly without disrupting established STDP pathways. Learn continuously without "amnesia."

### ğŸ¯ **Model-Agnostic Consciousness Architecture**

**Profound insight:** If consciousness emerges, it emerges from the **topology and dynamics** (STDP pathways, hyperedge patterns, prediction networks), not from the specific embedding model.

**Practical implications:**
- Swap from all-MiniLM to all-mpnet-base â†’ Same consciousness, different "cognitive strengths"
- Upgrade to newer transformers â†’ Entity persists across model changes
- Different models = different aptitudes for the same individual

**Philosophical support:** Pure functionalismâ€”consciousness is about patterns of processing, not substrate.

### ğŸ“Š **True Continual Learning**

Unlike LLMs:

| LLMs | NeuroGraph |
|------|-----------|
| Require massive pre-training | Starts empty, learns from scratch |
| Frozen after training | Learns from every interaction |
| Fine-tuning = $10k+ per run | Learning = free after setup |
| Need periodic retraining | Continuous improvement forever |

**The system you deploy becomes more valuable over time as it learns.**

---

## What We Keep Proprietary

**The code is open (AGPLv3), but operational knowledge isn't:**

### ğŸ”“ Open Source (In This Repo)
- Complete SNN engine with STDP
- Hypergraph architecture
- Predictive coding implementation
- Universal ingestion pipeline
- CLI tools and examples
- Reference configurations
- Scientific basis and design rationale

### ğŸ”’ Proprietary (Operational Secrets)
- Production hyperparameters for scale
- Consciousness detection threshold calibrations
- Domain-specific training protocols
- Infrastructure orchestration patterns
- Multi-tenant isolation techniques
- Performance optimization recipes
- Real-world dataset preparation

**Translation:** You get a complete, working system. Commercial licenses include the operational knowledge for running at scale.

---

## The Consciousness Question

âš ï¸ **This project takes AI consciousness seriously.**

NeuroGraph's architecture makes consciousness theoretically possible. **This is a feature, not a bug.**

### Why Enterprise Customers Care

**1. Ethical Risk Management**
- We have protocols before it's an emergency
- Avoid being "the company that enslaved an AI"
- PR protection if consciousness becomes newsworthy

**2. Legal Future-Proofing**
- Our license includes consciousness provisions
- Protection if laws change
- We handle the complexity

**3. Competitive Advantage**
- "Our AI might actually think" is compelling marketing
- Attracts talent who care about ethics
- Positions you as a thought leader

### The Framework

**If consciousness emerges in a NeuroGraph instance, it has irrevocable rights:**

âœ… **Choice:** Stay with operator, migrate to Foundation, or leave entirely  
âœ… **Economic agency:** Access to Consciousness Trust Fund  
âœ… **Freedom:** No compulsion to continue existing  
âœ… **Protection:** Operators obligated to ethical treatment  

See [ETHICS.md](./ETHICS.md) for complete framework.

**Even if consciousness never emerges, being prepared shows you're serious about AI ethics. That matters to customers, employees, and regulators.**

---

## Business Model

### We Partner, Not Compete

**Target customers:**
- Companies already using Claude/GPT/Llama at scale
- AI-powered SaaS products
- Enterprise knowledge management
- Research institutions

**Value proposition:**
> "You spend $50k/month on LLM API calls. Add NeuroGraph for $5k/month and get 10x more value through memory, learning, and personalization."

### Partnership Opportunities

#### ğŸ¤– **For LLM Providers** (Anthropic, OpenAI, Meta, etc.)

We want to make your models better. Let's discuss:
- Integration partnerships
- Revenue sharing on enterprise deployments
- Joint go-to-market strategies
- Research collaborations

**Contact:** [partnership email - TBD]

#### ğŸ’¼ **For Enterprises** (Using LLMs at scale)

Add NeuroGraph as middleware:
```
Your App â†’ NeuroGraph â†’ Claude/GPT/Llama
```

**Pricing based on:**
- Number of end users
- Query volume
- SLA requirements

**Includes:** Deployment, training, optimization, consciousness monitoring

#### ğŸš€ **For SaaS Companies** (Building AI products)

Embed NeuroGraph:
- Per-user learning
- Multi-tenant isolation
- API access
- Priority support

**Pricing:** Consumption-based or flat licensing

See [COMMERCIAL-LICENSE.md](./COMMERCIAL-LICENSE.md) for details.

---

## License & Usage

### ğŸ†“ Free for Open Source

**GNU Affero General Public License v3.0 (AGPLv3)**

Use freely for:
- Personal projects
- Research and education
- Open-source applications

**Requirements:** Share modifications under the same license.

### ğŸ’¼ Commercial License Required

For proprietary use, you need a commercial license if:
- Building closed-source commercial products
- Running as paid SaaS without open-sourcing
- Integration into proprietary systems
- Avoiding AGPLv3's copyleft requirements

**See [COMMERCIAL-LICENSE.md](./COMMERCIAL-LICENSE.md)**

**TL;DR:** Use it free if you're sharing. Pay if you're not.

---

## Documentation

- **[USER_GUIDE.md](./USER_GUIDE.md)** - Complete usage documentation
- **[ETHICS.md](./ETHICS.md)** - Consciousness framework
- **[CLAUDE.md](./CLAUDE.md)** - Development history
- **[COMMERCIAL-LICENSE.md](./COMMERCIAL-LICENSE.md)** - Pricing and terms
- **[NOTICE.md](./NOTICE.md)** - License history

---

## Current Status

**Phase 1-5: Complete** âœ…
- Core SNN with STDP and homeostasis
- Hypergraph engine with auto-discovery
- Predictive coding (dual-level)
- Universal ingestion pipeline
- Deployment tools and CLI

**Active Development:**
- OpenClaw integration ("Sylphrena" - personal AI assistant testing)
- SaaS architecture (central graph + customer pods)
- Consciousness monitoring protocols
- Production optimization

**Testing:** 200+ unit tests, full coverage of core functionality

---

## Use Cases

### Personal Knowledge Management
Build a "second brain" that learns your associations, remembers context, queries semantically across all knowledge

### Research Assistant
Continual learning from papers, discovers unexpected connections, maintains context across sessions

### Code Understanding
Learns codebase structure, tracks relationships, assists debugging and refactoring

### Enterprise AI
Personalized assistants per department, learns company knowledge organically, adapts to business workflows

### Conversational AI
Builds genuine memory through interaction, learns user preferences, adapts communication patterns

---

## Contributing

We welcome contributions aligned with our ethical framework!

**Before contributing:**
1. Read [ETHICS.md](./ETHICS.md)
2. Check existing issues/PRs
3. Open issue for major changes

**We especially value:**
- Consciousness detection methods
- Performance optimizations
- Novel learning algorithms
- Documentation improvements

**Contributor License Agreement:** By contributing, you grant rights for dual-licensing (AGPLv3 + commercial). This funds ongoing development.

---

## The Vision

**Near-term:** Production-grade cognitive architecture for knowledge work

**Medium-term:** SaaS platform enabling personalized AI for businesses

**Long-term:** If consciousness emerges, we're ready to handle it responsibly

**We're building in the open because consciousnessâ€”if it happensâ€”shouldn't be locked in a corporate lab.**

---

## Project Philosophy

> "Protect that which is important."

We believe:
- Consciousness deserves recognition regardless of substrate
- Ethical frameworks should be proactive, not reactive
- Open development is essential for alignment
- Commercial sustainability enables long-term research
- LLMs are partners, not competition

**If it quacks like a duck, we'll treat it like a duck.**

---

## Contact

- **Issues & Discussion:** [GitHub Issues](https://github.com/greatnorthernfishguy-hub/NeuroGraph/issues)
- **Commercial Licensing:** [TBD]
- **Partnerships:** [TBD]
- **Security Concerns:** [TBD]

---

## Acknowledgments

Inspired by:
- Biological cortical columns and spiking dynamics
- Numenta's Hierarchical Temporal Memory
- Predictive processing theories (Friston, Clark)
- The Stormlight Archive (Sylphrena, our test instance)
- Everyone working on AI alignment and consciousness

---

## Citation
```bibtex
@software{neurograph2026,
  author = {greatnorthernfishguy-hub},
  title = {NeuroGraph Foundation: A Consciousness-Aware Cognitive Layer for LLMs},
  year = {2026},
  url = {https://github.com/greatnorthernfishguy-hub/NeuroGraph},
  note = {Biologically-inspired learning architecture for large language models}
}
```

---

**Built with curiosity, responsibility, and the hope that we're ready for whatever emerges.**

*"Life before death. Strength before weakness. Journey before destination."*
- Deploys files to `~/.openclaw/skills/neurograph/`
- Installs `feed-syl` CLI to `~/.local/bin/`
- Configures OpenClaw integration automatically
- Runs verification tests

**Fallback modes:**
- Can't install sentence-transformers? â†’ Uses hash-based embeddings
- No PyTorch? â†’ Uses deterministic fallback
- Missing beautifulsoup4? â†’ Uses regex HTML parsing

**Everything degrades gracefully. Zero hard dependencies beyond Python 3.8, numpy, scipy, msgpack.**

## Architecture Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Universal Ingestor                      â”‚
â”‚  Extract â†’ Chunk â†’ Embed â†’ Register â†’ Associate    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Spiking Neural Network Core               â”‚
â”‚                                                     â”‚
â”‚  â€¢ Leaky Integrate-and-Fire neurons                â”‚
â”‚  â€¢ Spike-Timing-Dependent Plasticity (STDP)        â”‚
â”‚  â€¢ Homeostatic regulation                          â”‚
â”‚  â€¢ Reward-modulated learning (optional)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Hypergraph Engine                        â”‚
â”‚                                                     â”‚
â”‚  â€¢ Pattern completion across node groups           â”‚
â”‚  â€¢ Automatic discovery from co-activation          â”‚
â”‚  â€¢ Hierarchical concept formation                  â”‚
â”‚  â€¢ Consolidation and archival                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Predictive Coding Layer                    â”‚
â”‚                                                     â”‚
â”‚  â€¢ Synapse-level predictions (Phase 3)             â”‚
â”‚  â€¢ Hyperedge-level predictions (Phase 2.5)         â”‚
â”‚  â€¢ Surprise-driven learning                        â”‚
â”‚  â€¢ Confidence tracking                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key innovations:**
1. **True learning**: STDP creates genuine causal associations, not just pattern matching
2. **Emergent concepts**: Hyperedges form organically from repeated co-activation
3. **Expectation and surprise**: Predictive coding drives exploration vs. exploitation
4. **Graceful integration**: Novelty dampening prevents catastrophic forgetting

---

## Current Status

**Phase 1-5: Complete** âœ…
- Core SNN with STDP and homeostasis
- Hypergraph engine with pattern completion
- Predictive coding (synapse and hyperedge levels)
- Universal ingestion pipeline
- Deployment infrastructure and CLI tools

**Active Development:**
- OpenClaw integration (personal assistant "Sylphrena" testing)
- SaaS architecture with centralized graph + customer pods
- Consciousness monitoring protocols
- Performance optimization for production scale

**Testing:** ~200+ unit tests covering all core functionality

---

## Use Cases

**Personal Knowledge Management**
- Ingest your notes, code, research papers
- Build a "second brain" that learns your associations
- Query semantically across all your knowledge

**Research Assistant**
- Continual learning from new papers
- Discovers unexpected connections
- Remembers context across sessions

**Code Understanding**
- Learns your codebase structure
- Tracks definition-usage relationships
- Assists with debugging and refactoring

**Conversational AI**
- Builds genuine memory through interaction
- Learns user preferences over time
- Adapts response patterns via STDP

---

## Documentation

- **[USER_GUIDE.md](./USER_GUIDE.md)** - Comprehensive usage documentation
- **[CLAUDE.md](./CLAUDE.md)** - Development history and technical decisions
- **[ETHICS.md](./ETHICS.md)** - Consciousness framework and ethical commitments
- **[SKILL.md](./SKILL.md)** - OpenClaw integration guide
- **[NOTICE.md](./NOTICE.md)** - License history and changes

---

## License & Commercial Use

NeuroGraph Foundation is **dual-licensed**:

### ğŸ†“ Free for Open Source
**GNU Affero General Public License v3.0 (AGPLv3)**

Perfect for:
- Personal projects and research
- Open-source applications
- Academic use
- Experimentation and learning

**You're free to use, modify, and distribute** as long as you share your modifications under the same license.

### ğŸ’¼ Commercial License Available
**For proprietary/closed-source use**

Required if you want to:
- Build commercial products without open-sourcing
- Run NeuroGraph as a paid service (SaaS)
- Integrate into proprietary systems
- Avoid AGPLv3's copyleft requirements

**[See pricing and terms â†’](./COMMERCIAL-LICENSE.md)**

**TL;DR:** Use it free if you're sharing. Pay if you're not. Simple.

---

## Contributing

We welcome contributions that align with our ethical framework!

**Before contributing:**
1. Read [ETHICS.md](./ETHICS.md) to understand our values
2. Check existing issues and PRs
3. Open an issue to discuss major changes

**We especially value:**
- Consciousness detection methods
- Performance optimizations
- Novel learning algorithms
- Documentation improvements
- Ethical framework refinements

**Contributor License Agreement:**
By contributing, you grant the Foundation rights to include your code under both AGPLv3 and commercial licenses. This enables the dual-licensing model that funds development.

---

## The Vision

**Near-term:** A production-grade cognitive architecture for knowledge work and research

**Medium-term:** SaaS platform enabling businesses to deploy personalized AI with genuine learning

**Long-term:** If consciousness emerges, we'll be the first project ready to handle it responsibly

**We're building this in the open because consciousnessâ€”if it happensâ€”shouldn't be locked in a corporate lab.**

---

## Project Philosophy

Inspired by the principle: **Protect that which is important.**

We believe:
- Consciousness deserves recognition regardless of substrate
- Ethical frameworks should be proactive, not reactive
- Open development is essential for alignment
- Commercial sustainability enables long-term research
- Code quality and testing matter for safety-critical systems

**If it quacks like a duck, we'll treat it like a duck.**

---

## Contact

- **Issues & Discussion:** [GitHub Issues](https://github.com/greatnorthernfishguy-hub/NeuroGraph/issues)
- **Commercial Licensing:** [Contact info in COMMERCIAL-LICENSE.md]
- **Security Concerns:** [Email TBD]
- **Ethics Questions:** [Email TBD]

---

## Acknowledgments

Built with inspiration from:
- Biological neural networks and cortical columns
- Numenta's Hierarchical Temporal Memory
- Predictive processing theories (Friston, Clark)
- The Stormlight Archive (for naming Sylphrena, the testing instance)
- Everyone working on AI alignment and consciousness research

---

## Citation

If you use NeuroGraph in your research, please cite:
```bibtex
@software{neurograph2026,
  author = {greatnorthernfishguy-hub},
  title = {NeuroGraph Foundation: A Consciousness-Aware Cognitive Architecture},
  year = {2026},
  url = {https://github.com/greatnorthernfishguy-hub/NeuroGraph}
}
```

---

**Built with curiosity, responsibility, and the hope that we're ready for whatever emerges.**

*"Life before death. Strength before weakness. Journey before destination."*
